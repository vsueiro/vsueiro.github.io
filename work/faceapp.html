<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Vinicius Sueiro — FaceApp’s Racial Bias Experiment</title>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta property="og:image" content="" />

    <link rel="icon" type="image/svg+xml" href="../media/share/favicon.svg" />
    <link rel="icon" type="image/png" href="../media/share/favicon.png" />
    <link rel="stylesheet" href="../css/style.css" />
  </head>
  <body data-template="work" data-entrance="false">
    <nav class="full entrance">
      <a href="../">vsueiro</a>
    </nav>

    <header class="full">
      <div class="cover flow entrance max-1280" data-theme="faceapp">
        <span class="label"><span lang="pt-BR">Estadão</span> — 2019</span>
        <h1>FaceApp’s&nbsp;Racial Bias&nbsp;Experiment</h1>
        <div class="square" data-device="laptop">
          <figure>
            <img
              src="../media/portfolio/estadao/faceapp/laptop.gif"
              alt="Composition shows photos of Terry Crews before and after FaceApp filter was over-applied"
            />
            <figcaption class="screen-reader">
              A visual composition showcasing black actor Terry Crews as an
              animation: from his original photo, then to the result of the
              first image filter, then to the second, and so on. The result is a
              looped animation in which his face gets more white after each
              filter (and also extremely distorted by excessive wrinkles).
            </figcaption>
          </figure>
        </div>
      </div>

      <div class="flow max-800">
        <p>Besides Making You Old, FaceApp Makes Black People Look White</p>
      </div>
    </header>

    <section>
      <div class="flow max-800">
        <header>
          <h2>Context</h2>
        </header>

        <p>
          FaceApp, the Russian mobile application that became famous on the
          internet for creating an “elderly version” of yourself, saw its
          immense popularity turn into a pile of privacy questions.
        </p>
        <p>
          There were questions about what data is collected and shared, and
          fears about a company having a facial database of 150 million people
          worldwide.
        </p>
        <p>
          But the company’s questionable practices may stretch beyond that
          point.
        </p>
      </div>
    </section>

    <section>
      <div class="flow max-800">
        <header>
          <h2>Experiments</h2>
        </header>

        <p>
          What happens when you apply a filter again and again on the same
          photo? This is my curiosity speaking. First, I tried applying the male
          filter on my picture just to see some exaggerated features. I ended up
          looking like a caveman.
        </p>
        <p>
          Now it was time to try filters on other people. Who better than
          <a
            href="https://people.com/movies/idris-elba-sexiest-man-alive-2018-reveal/"
            target="_blank"
            >People’s sexiest man alive</a
          >
          choice of 2018? Thanks to Mariana Cunha for the tip ;)
        </p>
        <p>
          After a few iterations of the aging filter, I have turned Idris Elba
          into a bizarre-looking Santa Claus.
        </p>
      </div>

      <div class="flow max-800">
        <figure class="media">
          <img
            src="../media/portfolio/estadao/faceapp/idris-before-after.jpg"
            alt=""
          />
          <figcaption></figcaption>
        </figure>
      </div>

      <div class="flow max-800">
        <p>
          This is when it hit me. I have just
          <strong>reverse engineered</strong> FaceApp’s machine learning
          process. Well, kind of.
        </p>
        <p>
          At that point I got my team together to discuss ideas for the story
          and to design controlled experiments.
        </p>
      </div>
    </section>

    <section>
      <div class="flow max-800">
        <header>
          <h2>Result</h2>
        </header>

        <p>
          Our experiment applied the aging filter 5&times; on the same images.
          Despite the obvious distortions caused by artificial aging, all faces
          were whitened.
        </p>
        <p>
          This indicates a <strong>racially biased database</strong> may have
          been used to train the machine learning system that powers the app.
        </p>

        <ul class="metrics">
          <li>
            <strong>200k +</strong>
            <span>Views</span>
          </li>
          <li>
            <strong>5&times;</strong>
            <span>Filter</span>
          </li>
        </ul>
      </div>

      <div class="flow max-800">
        <p>
          For this project, a dozen pictures of black personalities were used —
          such as Terry Crews, Barack Obama, rapper Jay-Z, singer Iza and
          actress Lupita Nyong’o.
        </p>
      </div>

      <div class="flow max-1000">
        <figure class="media">
          <img
            src="../media/portfolio/estadao/faceapp/faceapp-mosaic.jpg"
            alt=""
          />
          <figcaption></figcaption>
        </figure>
      </div>

      <div class="flow max-800">
        <p>Here are some of the most evident outcomes:</p>

        <figure class="media">
          <img src="../media/portfolio/estadao/faceapp/terry.jpg" alt="" />
          <figcaption><strong>Terry Crews</strong>, Actor</figcaption>
        </figure>

        <figure class="media">
          <img src="../media/portfolio/estadao/faceapp/iza.jpg" alt="" />
          <figcaption><strong>Iza</strong>, Singer</figcaption>
        </figure>

        <figure class="media">
          <img src="../media/portfolio/estadao/faceapp/jayz.jpg" alt="" />
          <figcaption><strong>Jay-Z</strong>, Rapper</figcaption>
        </figure>

        <figure class="media">
          <img src="../media/portfolio/estadao/faceapp/viola.jpg" alt="" />
          <figcaption><strong>Viola Davis</strong>, Actress</figcaption>
        </figure>

        <figure class="media">
          <img src="../media/portfolio/estadao/faceapp/barack.jpg" alt="" />
          <figcaption><strong>Barack Obama</strong>, Politician</figcaption>
        </figure>

        <blockquote>
          <p>
            There is a human bias in collecting the data that was used to train
            the machine. I believe FaceApp had more images of white people than
            black people.
          </p>
          <cite
            ><a
              href="https://www.estadao.com.br/infograficos/link,alem-de-envelhecer-faceapp-embranquece-rostos-negros,1018384"
              target="_blank"
              >André de Carvalho</a
            >, Professor at the Institute of Mathematical and Computer Sciences
            at USP São Carlos</cite
          >
        </blockquote>

        <figure class="media">
          <img
            src="../media/portfolio/estadao/faceapp/biased-data.png"
            alt=""
          />
          <figcaption>
            The simplified diagrams above were published on the original
            article. They represent 2 image datasets used to train a machine.
            The first one is biased. Lighter or darker shades of each square
            represent the skin tone of the person portrayed in each photograph.
          </figcaption>
        </figure>

        <p>
          On a <strong>biased</strong> dataset, when searching for patterns, the
          computer identifies that being white is a characteristic of older
          people.
        </p>
        <p>
          If the training data is <strong>unbiased</strong>, the neural network
          doesn’t find any relationship between color and age. Thus, the machine
          highlights aspects such as skin roughness and baldness.
        </p>

        <hr />

        <p>
          This kind of “algorithmic racism” on a popular app is just the tip of
          the iceberg of an issue that society will face in the coming years.
        </p>
        <p>
          According to specialist Tarcízio Silva, facial recognition, credit
          scoring systems, job candidate analysis or criminal risk scores are
          also developed and deployed without much thought into their potential
          racial consequences.
        </p>
        <p>
          One of the ideas for avoiding biased algorithms lies behind the
          principle represented by FAT – an acronym for
          <strong>Fairness, Accountability and Transparency</strong>.
        </p>
        <p>
          That is, algorithms should treat everyone equally and companies should
          be responsible and transparent. The principle is discussed worldwide
          by experts in the field.
        </p>
      </div>
    </section>

    <section>
      <div class="flow max-800">
        <header>
          <h2>My Role</h2>
        </header>

        <ul class="list">
          <li>Idea</li>
          <li>Experimentation</li>
          <li>Team Management</li>
          <li>Content Editing</li>
        </ul>

        <p>
          Other contributors include
          <a href="https://twitter.com/br_romani" target="_blank"
            >Bruno Romani</a
          >
          (technolgy journalist) and
          <a href="http://brunoponceano.com/" target="_blank">Bruno Ponceano</a>
          (designer).
        </p>

        <div class="call-to-action">
          <a
            href="https://www.estadao.com.br/infograficos/link,alem-de-envelhecer-faceapp-embranquece-rostos-negros,1018384"
            target="_blank"
            class="button"
            ><span>Check it live</span></a
          >
        </div>
      </div>
    </section>

    <footer class="full">
      <div class="flow max-800">
        <p class="select">
          &#104;&#105;&#64;&#118;&#115;&#117;&#101;&#105;&#114;&#111;&#46;&#99;&#111;&#109;
        </p>
        <ul>
          <li>
            <a href="https://www.linkedin.com/in/vsueiro" target="_blank"
              >LinkedIn</a
            >
          </li>
          <li>
            <a href="https://read.cv/vsueiro" target="_blank">Read.cv</a>
          </li>
          <li>
            <a href="https://github.com/vsueiro" target="_blank">GitHub</a>
          </li>
        </ul>
        <p>
          Curiously enough, this website does not collect <i>any</i> data from
          you. No cookies, no trackers, nothing. I care for my privacy — and I
          also care for yours.
        </p>
      </div>
    </footer>

    <script src="../js/script.js" type="module"></script>

    <img src="https://metrics.vsueiro.com/api/pixel" alt="" />
  </body>
</html>
